{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the model\n",
    "from model.eval.evaluation import get_utility_metrics,stat_sim,privacy_metrics\n",
    "# Importing standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Acc       AUC  F1_Score\n",
      "lr   3.040229  0.031298 -0.009030\n",
      "dt   6.643464  0.055101  0.068646\n",
      "rf   3.767018  0.043888  0.047563\n",
      "mlp  2.026820  0.021140  0.012876\n",
      "svm  1.453578  0.034990 -0.047089\n",
      "           Acc       AUC  F1_Score\n",
      "lr   20.616235  0.277999  0.155583\n",
      "dt   16.838980  0.157002  0.173193\n",
      "rf   25.314771  0.307402  0.255489\n",
      "mlp  25.529737  0.470203  0.306502\n",
      "svm  32.347221  0.468133  0.249420\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                         0.01031                           0.101344   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              0.669588  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.042537                           0.228255   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              3.731642  \n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "adult_categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.386695                   0.216545   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.191876                                0.59256   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.442052                     0.424418  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.993638                   0.216545   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.001946                               0.792187   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.442052                     0.089173  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Adult/Stacked_Adult_fake_0_08_06_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Acc       AUC  F1_Score\n",
      "lr   0.030093  0.092485  0.098257\n",
      "dt   2.768583  0.248759  0.365205\n",
      "rf   0.100311  0.049458  0.281636\n",
      "mlp  0.090280  0.080031  0.336483\n",
      "svm  0.100311  0.593738  0.312016\n",
      "           Acc       AUC  F1_Score\n",
      "lr    0.050155  0.025700  0.180125\n",
      "dt   20.232721  0.336229  0.431800\n",
      "rf    0.100311  0.164513  0.281636\n",
      "mlp   0.060187  0.025091  0.207221\n",
      "svm   0.110342  0.488705  0.359409\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.007343                           0.076932   \n",
      "\n",
      "   Correlation Distance  \n",
      "0                2.1702  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.008682                                NaN   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.498667  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "\n",
    "credit_categorical = [\"Class\"]\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,credit_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              2.057963                   0.352515   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    2.228144                               0.848891   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.433713                     0.852653  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              2.128278                   0.352515   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    2.288457                               0.857918   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.433713                     0.848366  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Credit/Stacked_Credit_fake_2022-06-17T22-11-51_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Acc       AUC  F1_Score\n",
      "lr    6.533920  0.055569  0.060162\n",
      "dt   37.292375  0.261271  0.356532\n",
      "rf   26.295777  0.171300  0.284122\n",
      "mlp  14.008405  0.103277  0.136061\n",
      "svm   8.735241  0.076510  0.095981\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000007?line=15'>16</a>\u001b[0m fake_paths \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39mFakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_stacked.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000007?line=17'>18</a>\u001b[0m \u001b[39m# Storing and presenting the results as a dataframe\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000007?line=18'>19</a>\u001b[0m result_mat \u001b[39m=\u001b[39m get_utility_metrics(real_path,fake_paths,\u001b[39m\"\u001b[39;49m\u001b[39mMinMax\u001b[39;49m\u001b[39m\"\u001b[39;49m,classifiers_list, test_ratio \u001b[39m=\u001b[39;49m \u001b[39m0.20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000007?line=19'>20</a>\u001b[0m result_df  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result_mat,columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAcc\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mF1_Score\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000007?line=20'>21</a>\u001b[0m result_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m classifiers_list\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:138\u001b[0m, in \u001b[0;36mget_utility_metrics\u001b[0;34m(real_path, fake_paths, scaler, classifiers, test_ratio)\u001b[0m\n\u001b[1;32m    136\u001b[0m all_fake_results \u001b[39m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[39mfor\u001b[39;00m classifier \u001b[39min\u001b[39;00m classifiers:\n\u001b[0;32m--> 138\u001b[0m   fake_results \u001b[39m=\u001b[39m supervised_model_training(X_train_fake_scaled,y_train_fake,X_test_real_scaled,y_test_real,classifier)\n\u001b[1;32m    139\u001b[0m   all_fake_results\u001b[39m.\u001b[39mappend(fake_results)\n\u001b[1;32m    141\u001b[0m \u001b[39m# Storing the results across synthetic datasets \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:55\u001b[0m, in \u001b[0;36msupervised_model_training\u001b[0;34m(x_train, y_train, x_test, y_test, model_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(x_test)        \n\u001b[1;32m     54\u001b[0m acc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(y_test,pred)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m---> 55\u001b[0m auc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mroc_auc_score(y_test, predict,average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m\"\u001b[39;49m,multi_class\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39movr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     56\u001b[0m f1_score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mprecision_recall_fscore_support(y_test, pred,average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m2\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m [acc, auc, f1_score] \n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:563\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m multi_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    562\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmulti_class must be in (\u001b[39m\u001b[39m'\u001b[39m\u001b[39movo\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[1;32m    564\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39melif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    567\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:672\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    670\u001b[0m     classes \u001b[39m=\u001b[39m _unique(y_true)\n\u001b[1;32m    671\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes) \u001b[39m!=\u001b[39m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 672\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    673\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of classes in y_true not equal to the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    674\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcolumns in \u001b[39m\u001b[39m'\u001b[39m\u001b[39my_score\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    675\u001b[0m         )\n\u001b[1;32m    677\u001b[0m \u001b[39mif\u001b[39;00m multi_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39movo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.024906                           0.033738   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.802889  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.023951                           0.058602   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              5.135968  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "\n",
    "covtype_categorical = ['Wilderness_Area1','Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
    "                                        'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "                                        'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
    "                                        'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
    "                                        'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
    "                                        'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
    "                                        'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
    "                                        'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
    "                                        'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
    "                                        'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
    "                                        'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,covtype_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,covtype_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              1.174401                   0.355479   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.820841                               0.776075   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                      0.38621                      0.60754  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              1.464876                   0.355479   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.216346                               0.829421   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                      0.38621                     0.489045  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Covtype/Stacked_Covtype_fake_2022-06-17T21-13-43_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000010?line=6'>7</a>\u001b[0m classifiers_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmlp\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msvm\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000010?line=8'>9</a>\u001b[0m \u001b[39m# Storing and presenting the results as a dataframe\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000010?line=9'>10</a>\u001b[0m result_mat \u001b[39m=\u001b[39m get_utility_metrics(real_path,fake_paths,\u001b[39m\"\u001b[39;49m\u001b[39mMinMax\u001b[39;49m\u001b[39m\"\u001b[39;49m,classifiers_list, test_ratio \u001b[39m=\u001b[39;49m \u001b[39m0.20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000010?line=10'>11</a>\u001b[0m result_df  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result_mat,columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAcc\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mF1_Score\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations2.ipynb#ch0000010?line=11'>12</a>\u001b[0m result_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m classifiers_list\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:123\u001b[0m, in \u001b[0;36mget_utility_metrics\u001b[0;34m(real_path, fake_paths, scaler, classifiers, test_ratio)\u001b[0m\n\u001b[1;32m    121\u001b[0m data_fake_y \u001b[39m=\u001b[39m data_fake[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    122\u001b[0m data_fake_X \u001b[39m=\u001b[39m data_fake[:,:data_dim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 123\u001b[0m X_train_fake, _ , y_train_fake, _ \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39;49mtrain_test_split(data_fake_X ,data_fake_y, test_size\u001b[39m=\u001b[39;49mtest_ratio, stratify\u001b[39m=\u001b[39;49mdata_fake_y,random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m) \n\u001b[1;32m    125\u001b[0m \u001b[39m# Selecting scaling method\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m scaler\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMinMax\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2454\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2450\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2452\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2454\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[1;32m   2456\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2457\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2458\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   2459\u001b[0m     )\n\u001b[1;32m   2460\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:1613\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \n\u001b[1;32m   1585\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1613\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1614\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:1953\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1951\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   1952\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1953\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1954\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1956\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1957\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[1;32m   1961\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1962\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   1964\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.022765                           0.085176   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              3.680587  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.027566                           0.050871   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              5.655496  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "\n",
    "intrusion_categorical = [ 'protocol_type', 'service', 'flag', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "                                         'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "                                         'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "                                         'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "                                         'is_guest_login', 'class']\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,intrusion_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,intrusion_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.463484                   0.005297   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.049733                               0.812841   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.239995                     0.397246  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.522349                   0.005297   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.013951                               0.844914   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.239995                     0.312809  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Intrusion/Stacked_Intrusion_fake_2022-06-17T23-22-19_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Acc       AUC  F1_Score\n",
      "lr    1.9  0.011073  0.110673\n",
      "dt   12.0  0.261892  0.281349\n",
      "rf    4.7  0.044294  0.164411\n",
      "mlp   3.2  0.029948  0.121450\n",
      "svm   4.3  0.057868  0.197317\n",
      "      Acc       AUC  F1_Score\n",
      "lr    3.3  0.044570  0.109825\n",
      "dt   10.1  0.218796  0.241087\n",
      "rf    4.4  0.063226  0.157362\n",
      "mlp   4.3  0.064839  0.159393\n",
      "svm   2.8  0.056301  0.113383\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.040319                             0.0695   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              1.622212  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                         0.06053                           0.133287   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              1.946194  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "\n",
    "loan_categorical = [\"Family\",\"Education\",\"PersonalLoan\",\"Securities Account\",\"CD Account\",\"Online\",\"CreditCard\"]\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,loan_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,loan_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.866941                   0.607868   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.731929                               0.630668   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.494843                     0.584496  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              1.051202                   0.607868   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.600003                               0.719512   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.494843                     0.502076  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FakeFullRuns2/Loan/Stacked_Loan_fake_2022-06-17T22-18-10_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e02c531e8ff5d6eed2dc8059bd5a2a72070e573768ee9b31cbf1c39084ef69f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

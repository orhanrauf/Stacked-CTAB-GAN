{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the model\n",
    "from model.eval.evaluation import get_utility_metrics,stat_sim,privacy_metrics\n",
    "# Importing standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Acc       AUC  F1_Score\n",
      "lr   0.675607  0.012486  0.023175\n",
      "dt   5.435561  0.039246  0.053628\n",
      "rf   2.559116  0.032317  0.029699\n",
      "mlp  1.044119  0.020552  0.025506\n",
      "svm  1.207903  0.031563  0.055266\n",
      "           Acc       AUC  F1_Score\n",
      "lr   13.143618  0.031787  0.010457\n",
      "dt   12.498720  0.073215  0.109343\n",
      "rf    7.411199  0.063049  0.071733\n",
      "mlp   6.100932  0.068882  0.041898\n",
      "svm   7.963968  0.040522 -0.040550\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.009619                           0.103708   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              0.713914  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                         0.01072                           0.085723   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              1.909579  \n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "adult_categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.368103                   0.216545   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.176823                               0.589121   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.442052                     0.422175  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                               0.42432                   0.216545   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.074388                               0.652298   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.442052                     0.246971  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FullFakeRuns/Adult/Stacked_Adult_fake_2022-06-16T19-17-10_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Acc       AUC  F1_Score\n",
      "lr   0.060187  0.108840  0.227519\n",
      "dt   0.060187  0.235194  0.156307\n",
      "rf   0.100311  0.026510  0.281636\n",
      "mlp  0.090280  0.096818  0.336483\n",
      "svm  0.110342  0.670063  0.359409\n",
      "          Acc       AUC  F1_Score\n",
      "lr   0.050155  0.071868  0.180125\n",
      "dt   0.170529  0.294469  0.261158\n",
      "rf   0.110342  0.088575  0.324518\n",
      "mlp  0.080249  0.088283  0.289090\n",
      "svm  0.100311  0.512058  0.312016\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.006717                           0.057023   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.211947  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.007952                                NaN   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.977911  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "\n",
    "credit_categorical = [\"Class\"]\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,credit_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                               2.03691                   0.352515   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    2.235278                               0.854763   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.433713                     0.851098  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              2.127593                   0.352515   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    2.226732                               0.863058   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.433713                     0.854746  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Credit.csv\" \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FullFakeRuns/Credit/Stacked_Credit_fake_2022-06-14T23-41-29_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Acc       AUC  F1_Score\n",
      "lr    8.685211  0.066809  0.079061\n",
      "dt   35.961577  0.262951  0.344807\n",
      "rf   25.155093  0.186328  0.264734\n",
      "mlp  16.860116  0.121709  0.161265\n",
      "svm   8.705223  0.073105  0.081759\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000005?line=15'>16</a>\u001b[0m fake_paths \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39mFullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_stacked.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000005?line=17'>18</a>\u001b[0m \u001b[39m# Storing and presenting the results as a dataframe\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000005?line=18'>19</a>\u001b[0m result_mat \u001b[39m=\u001b[39m get_utility_metrics(real_path,fake_paths,\u001b[39m\"\u001b[39;49m\u001b[39mMinMax\u001b[39;49m\u001b[39m\"\u001b[39;49m,classifiers_list, test_ratio \u001b[39m=\u001b[39;49m \u001b[39m0.20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000005?line=19'>20</a>\u001b[0m result_df  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result_mat,columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAcc\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mF1_Score\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000005?line=20'>21</a>\u001b[0m result_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m classifiers_list\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:138\u001b[0m, in \u001b[0;36mget_utility_metrics\u001b[0;34m(real_path, fake_paths, scaler, classifiers, test_ratio)\u001b[0m\n\u001b[1;32m    136\u001b[0m all_fake_results \u001b[39m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[39mfor\u001b[39;00m classifier \u001b[39min\u001b[39;00m classifiers:\n\u001b[0;32m--> 138\u001b[0m   fake_results \u001b[39m=\u001b[39m supervised_model_training(X_train_fake_scaled,y_train_fake,X_test_real_scaled,y_test_real,classifier)\n\u001b[1;32m    139\u001b[0m   all_fake_results\u001b[39m.\u001b[39mappend(fake_results)\n\u001b[1;32m    141\u001b[0m \u001b[39m# Storing the results across synthetic datasets \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:55\u001b[0m, in \u001b[0;36msupervised_model_training\u001b[0;34m(x_train, y_train, x_test, y_test, model_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(x_test)        \n\u001b[1;32m     54\u001b[0m acc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(y_test,pred)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m---> 55\u001b[0m auc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mroc_auc_score(y_test, predict,average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m\"\u001b[39;49m,multi_class\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39movr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     56\u001b[0m f1_score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mprecision_recall_fscore_support(y_test, pred,average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m2\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m [acc, auc, f1_score] \n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:563\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m multi_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    562\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmulti_class must be in (\u001b[39m\u001b[39m'\u001b[39m\u001b[39movo\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[1;32m    564\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39melif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    567\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:672\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    670\u001b[0m     classes \u001b[39m=\u001b[39m _unique(y_true)\n\u001b[1;32m    671\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes) \u001b[39m!=\u001b[39m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 672\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    673\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of classes in y_true not equal to the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    674\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcolumns in \u001b[39m\u001b[39m'\u001b[39m\u001b[39my_score\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    675\u001b[0m         )\n\u001b[1;32m    677\u001b[0m \u001b[39mif\u001b[39;00m multi_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39movo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                         0.02414                           0.034118   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.713644  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.023457                           0.028487   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              3.848906  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "\n",
    "covtype_categorical = ['Wilderness_Area1','Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
    "                                        'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "                                        'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
    "                                        'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
    "                                        'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
    "                                        'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
    "                                        'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
    "                                        'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
    "                                        'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
    "                                        'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
    "                                        'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,covtype_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,covtype_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              1.185359                   0.355479   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.790869                               0.765737   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                      0.38621                     0.616198  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              1.310403                   0.355479   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.541237                               0.791491   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                      0.38621                     0.523335  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Covtype.csv\" \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FullFakeRuns/Covtype/Stacked_Covtype_fake_2022-06-16T20-15-52_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000006?line=6'>7</a>\u001b[0m classifiers_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmlp\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msvm\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000006?line=8'>9</a>\u001b[0m \u001b[39m# Storing and presenting the results as a dataframe\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000006?line=9'>10</a>\u001b[0m result_mat \u001b[39m=\u001b[39m get_utility_metrics(real_path,fake_paths,\u001b[39m\"\u001b[39;49m\u001b[39mMinMax\u001b[39;49m\u001b[39m\"\u001b[39;49m,classifiers_list, test_ratio \u001b[39m=\u001b[39;49m \u001b[39m0.20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000006?line=10'>11</a>\u001b[0m result_df  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result_mat,columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAcc\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mF1_Score\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raufakdemir/Documents/Thesis/Stacked-CTAB-GAN/Evaluations.ipynb#ch0000006?line=11'>12</a>\u001b[0m result_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m classifiers_list\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/model/eval/evaluation.py:123\u001b[0m, in \u001b[0;36mget_utility_metrics\u001b[0;34m(real_path, fake_paths, scaler, classifiers, test_ratio)\u001b[0m\n\u001b[1;32m    121\u001b[0m data_fake_y \u001b[39m=\u001b[39m data_fake[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    122\u001b[0m data_fake_X \u001b[39m=\u001b[39m data_fake[:,:data_dim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 123\u001b[0m X_train_fake, _ , y_train_fake, _ \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39;49mtrain_test_split(data_fake_X ,data_fake_y, test_size\u001b[39m=\u001b[39;49mtest_ratio, stratify\u001b[39m=\u001b[39;49mdata_fake_y,random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m) \n\u001b[1;32m    125\u001b[0m \u001b[39m# Selecting scaling method\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m scaler\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMinMax\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2454\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2450\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2452\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2454\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[1;32m   2456\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2457\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2458\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   2459\u001b[0m     )\n\u001b[1;32m   2460\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:1613\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \n\u001b[1;32m   1585\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1613\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1614\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/Documents/Thesis/Stacked-CTAB-GAN/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:1953\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1951\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   1952\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1953\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1954\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1956\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1957\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[1;32m   1961\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1962\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   1964\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.022765                           0.085176   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              3.680587  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.027566                           0.050871   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              5.655496  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "\n",
    "intrusion_categorical = [ 'protocol_type', 'service', 'flag', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "                                         'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "                                         'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "                                         'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "                                         'is_guest_login', 'class']\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,intrusion_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,intrusion_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.472383                   0.005297   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                     0.04827                               0.813234   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.239995                     0.445126  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                               0.40592                   0.005297   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.019606                                0.80337   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.239995                     0.358787  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Intrusion.csv\" \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FullFakeRuns/Intrusion/Stacked_Intrusion_fake_2022-06-17T19-14-55_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Acc       AUC  F1_Score\n",
      "lr    2.6  0.024855  0.096297\n",
      "dt   13.1  0.295907  0.309228\n",
      "rf    5.6  0.062500  0.215852\n",
      "mlp   5.4  0.049767  0.183524\n",
      "svm   4.4  0.069587  0.211652\n",
      "     Acc       AUC  F1_Score\n",
      "lr   1.6  0.007110  0.054814\n",
      "dt   7.2  0.170170  0.183736\n",
      "rf   4.0  0.032702  0.147589\n",
      "mlp  4.4  0.040238  0.146137\n",
      "svm  2.7  0.030962  0.106333\n"
     ]
    }
   ],
   "source": [
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_firstgen.csv\")\n",
    "\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.085716                           0.075765   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.006891  \n",
      "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
      "0                        0.048228                           0.051126   \n",
      "\n",
      "   Correlation Distance  \n",
      "0              2.381655  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "\n",
    "loan_categorical = [\"Family\",\"Education\",\"PersonalLoan\",\"Securities Account\",\"CD Account\",\"Online\",\"CreditCard\"]\n",
    "\n",
    "# Specifying the categorical columns of the dataset used\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_firstgen.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,loan_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n",
    "\n",
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_stacked.csv\")\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,loan_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "print(stat_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                               0.91315                   0.607868   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.725252                               0.630476   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.494843                     0.562917  \n",
      "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
      "0                              0.918861                   0.607868   \n",
      "\n",
      "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
      "0                    0.473246                               0.655172   \n",
      "\n",
      "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
      "0                     0.494843                     0.482453  \n"
     ]
    }
   ],
   "source": [
    "real_path = \"Real_Datasets/Loan.csv\" \n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_firstgen.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)\n",
    "\n",
    "fake_paths = glob.glob(\"FullFakeRuns/Loan/Stacked_Loan_fake_2022-06-17T19-20-50_stacked.csv\")\n",
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "print(privacy_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e02c531e8ff5d6eed2dc8059bd5a2a72070e573768ee9b31cbf1c39084ef69f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
